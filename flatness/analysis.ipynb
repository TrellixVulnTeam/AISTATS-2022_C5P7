{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"https://raw.githubusercontent.com/nicoguaro/matplotlib_styles/master\"\n",
    "style.use(\"results/style_sheet.mplstyle\")\n",
    "\n",
    "rc('figure', figsize=(8, 4))\n",
    "rc('savefig', bbox='tight')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import resnet18_narrow as resnet18\n",
    "from utils import get_loader\n",
    "from utils.train_utils import AverageMeter, accuracy\n",
    "import argparse\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pickle\n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {'mo': [0.0, 0.5, 0.9],  # momentum\n",
    "#               'wd': [0.0, 1e-4, 5e-4],  # weight decay\n",
    "#               'lr': [7e-3, 0.0085, 1e-2],  # learning rate\n",
    "#               'bs': [32, 128, 512],  # batch size\n",
    "#               }\n",
    "param_grid = {\n",
    "              'mo': [0.0, 0.5, 0.9],  # momentum\n",
    "              'width': [4, 6, 8],  # network width\n",
    "              'wd': [0.0, 1e-4, 5e-4],  # weight decay\n",
    "              'lr': [0.01, 0.032, 0.1],  # learning rate\n",
    "              'bs': [32, 128, 512],  # batch size\n",
    "              'skip': [True, False],  # skip connection\n",
    "              'batchnorm': [True, False]  # batchnorm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"measure, momentum, weight decay, learning rate, batch size\")\n",
    "idx = 0\n",
    "labels = [\"$\\epsilon$ sharpness\", \"Pac Bayes\", \"frobenius norm\", \"Fisher norm\", \"Trace\", \"Local entropy\", \"Low pass filter\"]\n",
    "for meas in [\"eps_flat\", \"pac_bayes\", \"fro_norm\", \"fim\", \"eig_trace\", \"local_entropy\", \"low_pass\"]:\n",
    "    print(f\"{meas} & \", end='')\n",
    "    for key, value in param_grid.items():\n",
    "        grid = copy.deepcopy(param_grid)\n",
    "        del grid[key]\n",
    "        \n",
    "        grid = list(ParameterGrid(grid))\n",
    "        corr = []\n",
    "        for params in grid:\n",
    "            flat_measure = []\n",
    "            hyper_param = []\n",
    "            for v in value:\n",
    "                params[f\"{key}\"] = v\n",
    "                name = f\"checkpoints/mnist/lenet/\" \\\n",
    "                       f\"*_0_{params['mo']}_{params['wd']}\" \\\n",
    "                       f\"_{params['lr']}_{params['bs']}_{False}\"\n",
    "\n",
    "                fol = glob.glob(name)[0]\n",
    "\n",
    "                with open(f\"{fol}/run_ms_0/measures.pkl\", 'rb') as f:\n",
    "                    measures = pickle.load(f)\n",
    "\n",
    "                if np.nan in list(measures.values()):\n",
    "                    continue\n",
    "\n",
    "                if measures['train_acc'] < 90:\n",
    "                    continue\n",
    "\n",
    "                flat_measure.append(measures[meas])\n",
    "                if v is True:\n",
    "                    hyper_param.append(1)\n",
    "                elif v is False:\n",
    "                    hyper_param.append(0)\n",
    "                else:\n",
    "                    hyper_param.append(v)\n",
    "            corr.append(scipy.stats.pearsonr(hyper_param, flat_measure)[0])\n",
    "\n",
    "        print(f\"{np.mean(corr):0.3f} & \", end='')\n",
    "    grid = list(ParameterGrid(param_grid))\n",
    "    \n",
    "    flat_measure = []\n",
    "    gen_gap = []\n",
    "\n",
    "    for params in grid:\n",
    "        name = f\"checkpoints/mnist/lenet/\" \\\n",
    "               f\"*_0_{params['mo']}_{params['wd']}\" \\\n",
    "               f\"_{params['lr']}_{params['bs']}_{False}\"\n",
    "\n",
    "        fol = glob.glob(name)[0]\n",
    "        with open(f\"{fol}/run_ms_0/measures.pkl\", 'rb') as f:\n",
    "            measures = pickle.load(f)\n",
    "\n",
    "        flat_measure.append(measures[meas])\n",
    "        gen_gap.append((100 - measures[\"val_acc\"]) - (100 - measures[\"train_acc\"]))\n",
    "    \n",
    "    print(f\"{scipy.stats.pearsonr(gen_gap, flat_measure)[0]:0.3f}\")\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter([f/np.max(flat_measure) for f in flat_measure], gen_gap)\n",
    "    ax.set_xlabel(f\"{labels[idx]}\")\n",
    "    idx+=1\n",
    "    ax.set_ylabel(\"Generalization gap\")\n",
    "    ax.set_title(f\"Pearson correlation: {scipy.stats.pearsonr(gen_gap, flat_measure)[0]:0.3f}\")\n",
    "    fig.savefig(f\"results/deep_learning/lenet_mnist/figure_{labels[idx-1]}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mo, width, wd, lr, bs, skip, batchnorm,  \n",
      "Empirical order &  -0.945 & -0.552 & -0.447 & -0.880 & 0.997 & 0.091 & -0.429 & "
     ]
    }
   ],
   "source": [
    "# # same results as fantastic papers\n",
    "\n",
    "for x in param_grid.keys():\n",
    "    print(x, end=', ')\n",
    "print(' ')\n",
    "# # pick a measure\n",
    "# for meas in [\"eps_flat\", \"pac_bayes\", \"fro_norm\", \"fim\", \"eig_trace\", \"local_entropy\", \"low_pass\"]:\n",
    "#     print(f\"{meas} & \", end='')\n",
    "#     # pick a hyper-parameter\n",
    "#     for key, value in param_grid.items():\n",
    "#         grid = copy.deepcopy(param_grid)\n",
    "#         del grid[key]\n",
    "        \n",
    "#         grid = list(ParameterGrid(grid))\n",
    "#         corr = []\n",
    "#         # loop over all other set of hyper-parameters\n",
    "#         for params in grid:\n",
    "#             flat_measure = []\n",
    "#             gen_gap = []\n",
    "#             # and just vary a single hyper-parameter that we picked\n",
    "#             for v in value:\n",
    "#                 params[f\"{key}\"] = v\n",
    "#                 name = f\"checkpoints/mnist/lenet/\" \\\n",
    "#                        f\"*_0_{params['mo']}_{params['wd']}\" \\\n",
    "#                        f\"_{params['lr']}_{params['bs']}_{False}\"\n",
    "\n",
    "#                 fol = glob.glob(name)[0]\n",
    "\n",
    "#                 with open(f\"{fol}/run_ms_0/measures.pkl\", 'rb') as f:\n",
    "#                     measures = pickle.load(f)\n",
    "                \n",
    "#                 # record flatness and gen_gap for it\n",
    "#                 flat_measure.append(measures[meas])\n",
    "#                 gen_gap.append((100 - measures[\"val_acc\"]) - (100 - measures[\"train_acc\"]))\n",
    "#             # compute tau and append (this is inner tau in equation 4 of fantastic)\n",
    "#             # just that our tau is not kendall but pearson\n",
    "#             corr.append(scipy.stats.kendalltau(gen_gap, flat_measure)[0])\n",
    "\n",
    "#         # this is mean over a picked hyper-parameter\n",
    "#         print(f\"{np.mean(corr):0.3f} & \", end='')\n",
    "#     print(' ')\n",
    "\n",
    "print(\"Empirical order & \", end=' ')\n",
    "# pick a hyper-parameter\n",
    "for key, value in param_grid.items():\n",
    "    grid = copy.deepcopy(param_grid)\n",
    "    del grid[key]\n",
    "\n",
    "    grid = list(ParameterGrid(grid))\n",
    "    corr = []\n",
    "    # loop over all other set of hyper-parameters\n",
    "    for params in grid:\n",
    "        gen_gap = []\n",
    "        hyp = []\n",
    "        # and just vary a single hyper-parameter that we picked\n",
    "        for v in value:\n",
    "            params[f\"{key}\"] = v\n",
    "#             name = f\"checkpoints/mnist/lenet/\" \\\n",
    "#                    f\"*_0_{params['mo']}_{params['wd']}\" \\\n",
    "#                    f\"_{params['lr']}_{params['bs']}_{False}\"\n",
    "            name = f\"checkpoints/cifar10/*_0_{params['mo']}_{params['width']}_{params['wd']}_\" \\\n",
    "                   f\"{params['lr']}_{params['bs']}_{params['skip']}_{params['batchnorm']}\"\n",
    "\n",
    "            fol = glob.glob(name)[0]\n",
    "\n",
    "            try:\n",
    "                with open(f\"{fol}/run_ms_0/measures.pkl\", 'rb') as f:\n",
    "                    measures = pickle.load(f)\n",
    "                if measures[\"train_acc\"] < 99:\n",
    "                    pass\n",
    "                else:\n",
    "                    # record flatness and hyper-parameter for it\n",
    "                    gen_gap.append((100 - measures[\"val_acc\"]) - (100 - measures[\"train_acc\"]))\n",
    "                    hyp.append(v)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "        # compute tau and append (this is inner tau in equation 4 of fantastic)\n",
    "        # just that our tau is not kendall but pearson\n",
    "        if len(gen_gap) > 1:\n",
    "            corr.append(scipy.stats.kendalltau(hyp, gen_gap)[0])\n",
    "\n",
    "    # this is mean over a picked hyper-parameter\n",
    "    print(f\"{np.mean(corr):0.3f} & \", end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
