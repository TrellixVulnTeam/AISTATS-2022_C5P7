{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo = \"https://raw.githubusercontent.com/nicoguaro/matplotlib_styles/master\"\n",
    "# style.use(\"results/style_sheet.mplstyle\")\n",
    "\n",
    "# rc('figure', figsize=(8, 4))\n",
    "# rc('savefig', bbox='tight')\n",
    "# plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import resnet18_narrow as resnet18\n",
    "from utils import get_loader\n",
    "from utils.train_utils import AverageMeter, accuracy\n",
    "import argparse\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pickle\n",
    "from tqdm import tqdm \n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'mo': [0.0, 0.5, 0.9],  # momentum\n",
    "              'width': [4, 6, 8],  # network width\n",
    "              'wd': [0.0, 1e-4, 5e-4],  # weight decay\n",
    "              'lr': [0.01, 0.0075, 0.005],  # learning rate\n",
    "              'bs': [32, 128, 512],  # batch size\n",
    "              'skip': [False, True], # skip\n",
    "              'batchnorm': [False, True]  # batchnorm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/cifar10/resnet/895_0_0.5_6_0.0001_0.0075_512_False_False/run_ms_0/measures.pkl\n",
      "checkpoints/cifar10/resnet/533_0_0.9_8_0.0_0.01_32_False_False/run_ms_0/measures.pkl\n",
      "checkpoints/cifar10/resnet/585_0_0.9_4_0.0_0.0075_32_False_False/run_ms_0/measures.pkl\n",
      "checkpoints/cifar10/resnet/585_0_0.9_4_0.0_0.0075_32_False_False/run_ms_0/measures.pkl\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting needs\n",
    "labels = [\"$\\epsilon$ sharpness\", \"Pac Bayes\", \"$||H||_{F}$\", \"Fisher norm\", \"local_entropy_grad_norm\", \"Classical Entropy\", \"Trace\", \"Low pass filter\", \"local_entropy\"]\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# [\"eps_flat\", \"pac_bayes\", \"fro_norm\", \"fim\", \"local_entropy_grad_norm\", \"shannon_entropy\", \"eig_trace\", \"low_pass\", \"local_entropy\"]\n",
    "\n",
    "for meas in [\"local_entropy_grad_norm\"]:\n",
    "    plotting_needs = [[], []]\n",
    "    \n",
    "    for fol in glob.glob(\"checkpoints/cifar10/resnet/*\"):        \n",
    "        try:\n",
    "            with open(f\"{fol}/run_ms_0/measures.pkl\", 'rb') as f:\n",
    "                measures = pickle.load(f)\n",
    "        except:\n",
    "            print(f\"{fol}/run_ms_0/measures.pkl\")\n",
    "            continue\n",
    "            \n",
    "        # discard model with less cross-entropy               \n",
    "        if measures[\"train_loss\"] > 0.01:\n",
    "            continue\n",
    "\n",
    "        # record flatness and gen_gap for it\n",
    "        try:\n",
    "            plotting_needs[1] += [measures[meas]]\n",
    "            plotting_needs[0] += [-measures[\"val_acc\"] + measures[\"train_acc\"]]\n",
    "        except:\n",
    "            print(f\"{fol}/run_ms_0/measures.pkl\")\n",
    "            continue\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(plotting_needs[0], plotting_needs[1])\n",
    "#     ax.set_ylim([0,0.06])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same results as fantastic papers\n",
    "print(\"Measure\")\n",
    "for x in param_grid.keys():\n",
    "    print(x, end=', ')\n",
    "print(' ')\n",
    "# labels = [\"$\\epsilon$ sharpness\", \"Pac Bayes\", \"$||H||_{F}$\", \"Fisher norm\", \"Local entropy\", \"Classical Entropy\", \"Trace\", \"Low pass filter\"]\n",
    "labels = [\"local_entropy_grad_norm\"]\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "idx = 0\n",
    "# pick a measure\n",
    "for meas in [\"local_entropy_grad_norm\"]:\n",
    "    print(f\"{labels[idx]} & \", end='')\n",
    "\n",
    "    # pick a hyper-parameter\n",
    "    for key, value in param_grid.items():\n",
    "        grid = copy.deepcopy(param_grid)\n",
    "        del grid[key]\n",
    "        \n",
    "        grid = list(ParameterGrid(grid))\n",
    "        corr = []\n",
    "        # loop over all other set of hyper-parameters\n",
    "        for params in grid:\n",
    "            flat_measure = []\n",
    "            gen_gap = []\n",
    "            # and just vary a single hyper-parameter that we picked\n",
    "            for v in value:\n",
    "                params[key] = v\n",
    "                # cifar\n",
    "                name = f\"checkpoints/cifar10/resnet/\" \\\n",
    "                       f\"*_0_{params['mo']}_{params['width']}_{params['wd']}_\" \\\n",
    "                       f\"{params['lr']}_{params['bs']}_{params['skip']}_{params['batchnorm']}\"\n",
    "                \n",
    "                fol = glob.glob(name)[0]\n",
    "                    \n",
    "                try:\n",
    "                    with open(f\"{fol}/run_ms_0/measures.pkl\", 'rb') as f:\n",
    "                        measures = pickle.load(f)\n",
    "                except:\n",
    "                    continue\n",
    "                # discard model with less cross-entropy               \n",
    "                if measures[\"train_loss\"] > 0.01:\n",
    "                    continue\n",
    "\n",
    "                # record flatness and gen_gap for it\n",
    "                try:\n",
    "                    flat_measure.append(measures[meas])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                gen_gap.append(-measures[\"val_acc\"]+measures[\"train_acc\"])\n",
    "\n",
    "            # compute tau and append (this is inner tau in equation 4 of fantastic)\n",
    "            # just that our tau is not kendall but pearson\n",
    "            if len(gen_gap) > 1:\n",
    "                c = scipy.stats.kendalltau(flat_measure, gen_gap)[0]\n",
    "                if not math.isnan(c):\n",
    "                    corr.append(c)\n",
    "        # this is mean over a picked hyper-parameter\n",
    "        print(f\"{np.mean(corr):0.4f} & \", end='')\n",
    "    idx+=1\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Empirical order & \", end=' ')\n",
    "for key, value in param_grid.items():\n",
    "    print(f\"{key} &\", end=' ')\n",
    "print(' ')\n",
    "\n",
    "for key, value in param_grid.items():\n",
    "\n",
    "    grid = copy.deepcopy(param_grid)\n",
    "    del grid[key]\n",
    "\n",
    "    grid = list(ParameterGrid(grid))\n",
    "    corr = []\n",
    "    # loop over all other set of hyper-parameters\n",
    "    for params in grid:\n",
    "        gen_gap = []\n",
    "        hyp = []\n",
    "        # and just vary a single hyper-parameter that we picked\n",
    "        for v in value:\n",
    "            params[f\"{key}\"] = v\n",
    "            # cifar\n",
    "            name = f\"checkpoints/cifar10/resnet/\" \\\n",
    "                   f\"*_0_{params['mo']}_{params['width']}_{params['wd']}_\" \\\n",
    "                   f\"{params['lr']}_{params['bs']}_{params['skip']}_{params['batchnorm']}\"\n",
    "\n",
    "            fol = glob.glob(name)[0]\n",
    "\n",
    "            try:\n",
    "                with open(f\"{fol}/run_ms_0/measures.pkl\", 'rb') as f:\n",
    "                    measures = pickle.load(f)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if measures[\"train_loss\"] > 0.01:\n",
    "                continue\n",
    "            else:\n",
    "                # record flatness and hyper-parameter for it\n",
    "                gen_gap.append((100 - measures[\"val_acc\"]))\n",
    "                if v is True:\n",
    "                    hyp.append(1)\n",
    "                elif v is False:\n",
    "                    hyp.append(0)\n",
    "                else:\n",
    "                    hyp.append(v)\n",
    "\n",
    "        # compute tau and append (this is inner tau in equation 4 of fantastic)\n",
    "        # just that our tau is not kendall but pearson\n",
    "        if len(gen_gap) > 1:\n",
    "            c = scipy.stats.kendalltau(hyp, gen_gap)[0]\n",
    "            if not math.isnan(c):\n",
    "                corr.append(c)\n",
    "    # this is mean over a picked hyper-parameter\n",
    "    print(f\"{np.mean(corr):0.4f} & \", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"measure, momentum, weight decay, learning rate, batch size\")\n",
    "idx = 0\n",
    "labels = [\"$\\epsilon$ sharpness\", \"Pac Bayes\", \"frobenius norm\", \"Fisher norm\", \"Trace\", \"Local entropy\", \"Low pass filter\"]\n",
    "for meas in [\"eps_flat\", \"pac_bayes\", \"fro_norm\", \"fim\", \"eig_trace\", \"local_entropy\", \"low_pass\"]:\n",
    "    print(f\"{meas} & \", end='')\n",
    "    for key, value in param_grid.items():\n",
    "        grid = copy.deepcopy(param_grid)\n",
    "        del grid[key]\n",
    "        \n",
    "        grid = list(ParameterGrid(grid))\n",
    "        corr = []\n",
    "        for params in grid:\n",
    "            flat_measure = []\n",
    "            hyper_param = []\n",
    "            for v in value:\n",
    "                params[f\"{key}\"] = v\n",
    "                #mnist\n",
    "#                 name = f\"checkpoints/mnist/lenet/\" \\\n",
    "#                        f\"*_0_{params['mo']}_{params['wd']}\" \\\n",
    "#                        f\"_{params['lr']}_{params['bs']}_{False}\"\n",
    "                # cifar\n",
    "#                 name = f\"checkpoints/cifar10/resnet/\" \\\n",
    "#                        f\"*_0_{params['mo']}_{params['width']}_{params['wd']}_\" \\\n",
    "#                        f\"{params['lr']}_{params['bs']}_{params['skip']}_{params['batchnorm']}\"\n",
    "\n",
    "                fol = glob.glob(name)[0]\n",
    "\n",
    "                with open(f\"{fol}/run_ms_0/measures.pkl\", 'rb') as f:\n",
    "                    measures = pickle.load(f)\n",
    "\n",
    "                if np.nan in list(measures.values()):\n",
    "                    continue\n",
    "\n",
    "                if measures['train_loss'] > 0.01:\n",
    "                    continue\n",
    "                else:\n",
    "                    flat_measure.append(measures[meas])\n",
    "                    if v is True:\n",
    "                        hyper_param.append(1)\n",
    "                    elif v is False:\n",
    "                        hyper_param.append(0)\n",
    "                    else:\n",
    "                        hyper_param.append(v)\n",
    "            if len(hyper_param)>1:\n",
    "                corr.append(scipy.stats.pearsonr(hyper_param, flat_measure)[0])\n",
    "\n",
    "        print(f\"{np.mean(corr):0.3f} & \", end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
